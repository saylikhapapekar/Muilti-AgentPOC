import os

from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings
from pathlib import Path
from langchain.memory.buffer import ConversationBufferMemory
import json

MEMORY_BASE_PATH = "./../user_memory"

# Ensure the base directory exists
Path(MEMORY_BASE_PATH).mkdir(parents=True, exist_ok=True)

def load_user_memory(user_id: str):
    """
    Load or create a Chroma memory with the given user ID.

    Args:
        user_id (str): The unique ID for the user.

    Returns:
        ConversationBufferMemory: The memory object for the user.
    """
    os.makedirs(MEMORY_BASE_PATH, exist_ok=True)
    user_memory_path = os.path.join(MEMORY_BASE_PATH, f"{user_id}_memory_index")

    # Load or initialize Chroma vector store
    if os.path.exists(user_memory_path):
        vector_store = Chroma(persist_directory=user_memory_path, embedding_function=OpenAIEmbeddings())
    else:
        os.makedirs(user_memory_path, exist_ok=True)
        vector_store = Chroma(persist_directory=user_memory_path, embedding_function=OpenAIEmbeddings())

    stored_docs = vector_store.get()["documents"]

    memory = ConversationBufferMemory(vector_store=vector_store, memory_key="chat_history")

    for i in range(0, len(stored_docs), 2):
        memory.save_context({"input": stored_docs[i]}, {"output": stored_docs[i+1]})

    # Return the VectorStoreMemory for this user
    return memory, vector_store


def get_portfolio_from_memory(user_id: str) -> dict:
    """
    Retrieve the most recent portfolio data from the vector store.

    Args:
        user_id (str): The unique ID of the user.

    Returns:
        dict: The most recent portfolio data, or empty dict if none found.
    """
    _, vector_store = load_user_memory(user_id)

    # Search for portfolio data in vector store
    results = vector_store.similarity_search(
        "PORTFOLIO_DATA_"+str(user_id),
        k=1  # Get the most recent portfolio data
    )

    for doc in results:
        if doc.page_content.startswith("PORTFOLIO_DATA_"+str(user_id)):
            try:
                # Extract and parse the JSON data
                json_str = doc.page_content.replace("PORTFOLIO_DATA_"+str(user_id), "").strip()
                return json.loads(json_str)
            except json.JSONDecodeError:
                print("Error parsing portfolio data from vector store")

    return {}



def save_user_memory(user_id: str, input_text: str, output_text: str, portfolio_data: dict = None):
    """
    Save user conversation history and portfolio data to memory.

    Args:
        user_id (str): The unique ID of the user.
        input_text (str): The input provided by the user.
        output_text (str): The response generated by the agent.
        portfolio_data (dict, optional): Portfolio data to be stored if available.
    """
    user_memory, vector_store = load_user_memory(user_id)

    # Add user input and agent output to memory buffer
    user_memory.save_context({"input": input_text}, {"output": output_text})

    # Store regular conversation in vector store
    vector_store.add_texts([input_text, output_text])

    # If portfolio data is provided, store it with a special prefix
    if portfolio_data:
        portfolio_marker = "PORTFOLIO_DATA"
        portfolio_text = f"{portfolio_marker}_{user_id} {json.dumps(portfolio_data)}"
        vector_store.add_texts([f"{user_id}_JSON_PORTFOLIO", portfolio_text])

        # Also save in conversation buffer for immediate context
        user_memory.save_context(
            {"input": "System: Storing portfolio data"},
            {"output": portfolio_text}
        )

    # Persist the vector store data
    vector_store.persist()
    print(user_memory.load_memory_variables({}))

